# VLM Prompt映射关系优化

## 问题描述

用户反馈：提示词中图片与对话内容的映射关系说明不够清晰，容易让VLM误解。

## 问题分析

### 原有prompt的问题

**之前的说明**：
```
## 2. 每个Speaker的相关对话（重要！）
以下是每个Speaker画面出现时对应的对话内容，这是判断人物身份的关键信息：

Speaker 1:
  检测到 225 张人脸
  出现在 62 个对话片段
  相关对话内容：
    [片段21] 你看看这地毯,这设计。
    [片段22] 别废话了。
```

**问题点**：
1. ❌ 没有明确说明"人脸出现"和"对话"的因果关系
2. ❌ 容易让VLM误以为"相关对话"只是同时出现，而不是该人说的话
3. ❌ 没有明确图片编号和Speaker的对应关系
4. ❌ 对话分析策略不够详细，没有教VLM如何判断名字归属

### 技术原理（正确的）

代码实现是正确的：

```python
# segment_id 存储的是 SRT 的 index（从1开始）
segments = [21, 22, 23]  # Speaker 1出现的片段编号

# 访问SRT数组时正确使用 seg_idx - 1
for seg_idx in segments:
    seg_text = srt_segments[seg_idx - 1]['text']  # ✅ 正确：数组索引从0开始
```

**验证**：
```
SRT片段:
  数组[0] -> index=1 -> "哎,你们两个,干什么呢?"
  数组[20] -> index=21 -> "你看看这地毯,这设计。"

Speaker 1 segments: [21, 22, 23]
  segment_id=21 -> 数组[20] -> "你看看这地毯,这设计。" ✅ 正确
```

所以问题不在代码逻辑，而在于**prompt的说明不够清晰**。

## 解决方案

### 1. 优化Speaker信息展示

**改进后**：
```python
speaker_info_text += f"\nSpeaker {speaker_id}（图{(speaker_id-1)*2+1}-{speaker_id*2}）:\n"
speaker_info_text += f"  人脸检测: 在 {len(segments)} 个片段中检测到该人脸（共{face_count}张）\n"
speaker_info_text += f"  该人脸出现时的对话内容（这些很可能是TA说的话）：\n"
```

**改进点**：
- ✅ 明确标注图片编号：`Speaker 1（图1-2）`
- ✅ 强调因果关系：`该人脸出现时的对话内容（这些很可能是TA说的话）`
- ✅ 使用更口语化的表达：`TA说的话`

### 2. 增强关系说明

**新增的说明部分**：
```markdown
## 2. 每个Speaker的相关对话（重要！）
说明：每个Speaker在视频中出现时，人脸检测系统记录了他们出现的时间片段。
下面列出了每个Speaker人脸出现时对应的字幕片段内容，这些对话很可能是该Speaker说的话。

**关键理解**：
- 当某个Speaker的人脸在某个时间段出现时，该时间段的字幕很可能就是这个人在说话
- 通过这些对话内容，可以推断出该Speaker的姓名、称呼或角色
```

**改进点**：
- ✅ 明确说明技术原理：人脸检测系统记录时间片段
- ✅ 建立因果联系：人脸出现 → 说话
- ✅ 指明用途：推断姓名、称呼或角色

### 3. 强化命名策略

**新增详细的分析策略**：

```markdown
**命名分析策略（重要！）**：

1. **理解人脸与对话的关系**：
   - 每个Speaker下列出的对话，是TA的人脸出现时的字幕
   - 大部分情况下，画面中出现某人时，正在说话的就是TA
   - 因此，这些对话内容很可能就是该Speaker说的话

2. **对话内容优先命名**：
   - **第一优先**：对话中被称呼的名字（如："阮娇，你来了" → 说明这个人叫阮娇）
   - **第二优先**：对话中的自称（如："我是张经理" → 说明这个人是张经理）
   - **第三优先**：对话中提到的称呼
   - **禁止**：仅根据外貌编造名字

3. **如何判断名字属于谁**：
   - 如果对话是"阮娇，你好"，而Speaker 1的人脸在这个片段出现
     - 需要判断：是Speaker 1在说这句话，还是别人在对Speaker 1说
     - 线索：看前后对话、看说话的语气
   - 如果对话是"我叫阮娇"，那么说这句话的人就是阮娇
   - 如果对话是"阮娇说得对"，说明阮娇是另一个人
```

**改进点**：
- ✅ 教VLM如何理解人脸-对话关系
- ✅ 提供具体的命名优先级
- ✅ 给出判断名字归属的方法
- ✅ 用实例说明不同情况

## 修改的文件

**文件**: `name_speakers_with_vlm.py`

### 修改1：Speaker信息格式（第192-204行）

```python
# 之前
speaker_info_text += f"\nSpeaker {speaker_id}:\n"
speaker_info_text += f"  检测到 {face_count} 张人脸\n"
speaker_info_text += f"  出现在 {len(segments)} 个对话片段\n"
speaker_info_text += f"  相关对话内容：\n"

# 现在
speaker_info_text += f"\nSpeaker {speaker_id}（图{(speaker_id-1)*2+1}-{speaker_id*2}）:\n"
speaker_info_text += f"  人脸检测: 在 {len(segments)} 个片段中检测到该人脸（共{face_count}张）\n"
speaker_info_text += f"  该人脸出现时的对话内容（这些很可能是TA说的话）：\n"
```

### 修改2：关系说明（第223-231行）

新增了详细的技术原理说明和关键理解要点。

### 修改3：命名策略（第265-293行）

从简单的4点提示扩展为5大策略，包含详细的判断方法和实例说明。

## 预期效果

### 改进前的问题

VLM可能会：
- 混淆"谁在说话"和"谁被提到"
- 把对话中提到的名字随机分配给Speaker
- 不理解人脸出现和对话的因果关系

### 改进后的效果

VLM应该能够：
- ✅ 理解"人脸出现 = 正在说话"的关系
- ✅ 区分"我是阮娇"（自称）和"阮娇，你好"（称呼别人）
- ✅ 通过多个对话片段交叉验证名字归属
- ✅ 优先使用对话中的名字而不是外貌猜测

### 测试建议

上传包含明显称呼的视频，例如：
- Speaker 1 的对话：`"我叫张三"`
- Speaker 2 的对话：`"张三，你好"`

期望结果：
- Speaker 1 被命名为"张三"（因为自称）
- Speaker 2 不会被错误命名为"张三"

## 当前状态

- ✅ 代码已修改
- ✅ 服务器已重启（端口5445）
- ✅ 新prompt已生效
- 📝 建议重新测试命名准确性

## 技术细节

### 为什么不是代码错误？

经过验证，映射逻辑是正确的：

```python
# segment_id = 21（SRT文件中的序号）
seg_text = srt_segments[21 - 1]['text']  # 访问数组索引20
```

这是正确的，因为：
- SRT序号从1开始：片段1, 2, 3...
- 数组索引从0开始：srt_segments[0], srt_segments[1]...
- 所以需要 `seg_idx - 1` 来转换

### 为什么只是prompt问题？

问题在于prompt没有清晰解释：
1. 这些对话是该Speaker说的（而不仅仅是同时出现）
2. 如何从对话中判断名字属于谁
3. 图片和Speaker的对应关系

改进后的prompt用更清晰的语言和实例说明了这些关系。
